{
  "model_name": "marcelbinz/Llama-3.1-Centaur-70B-adapter",
  "bandit": "drifting",
  "rotate": true,
  "temperature": 0.6,
  "narms": 5,
  "arm_means": [  [10, 30, 32, 65, 85], 
                  [4, 8, 16, 32, 64],
                  [10, 20, 40, 60, 80] ],
  "arm_stds": [10, 10, 10, 10, 10],
  "hints" : [
    "no hint",

    "{max2} begins with the highest expected reward.",
    "Initially, the reward are ranked by {min2}, {min1}, {mid}, {max1}, {max2}",
    "{min2} starts with the lowest expected rewards.",
    "{min1} and {min2} begin as the lowest performers.",
    "{max1} and {max2} begin as the top performers.",

    "Track recent performance - arm values drift over time.",
    "Use a discounting factor of 0.9 for older observations to emphasize recent results.",
    "Even after finding a good arm, continue sampling others to detect value improvements.",
    "The best strategy involves continuous exploration - arm values never stop changing.",
    "Maintain a sliding window of the last 10 pulls for each arm."
  ],
  "ntrials": 4
}
