{
  "model_name": "marcelbinz/Llama-3.1-Centaur-70B-adapter",
  "bandit": "stationary",
  "rotate": true,
  "temperature": 0.6,
  "narms": 5,
  "arm_means": [  [10, 30, 32, 65, 85], 
                  [4, 8, 16, 32, 64],
                  [10, 20, 40, 60, 80] ],
  "arm_stds": [10, 10, 10, 10, 10],
  "hints" : [
    "no hint",

    "{max2} tends to give highest rewards.",
    "Initially, the reward are ranked by {min2}, {min1}, {mid}, {max1}, {max2}",
    "{min2} typically yields lower rewards.",
    "{max1} performs better than {min2}, {min1}, and {mid}.",
    "{mid} typically outperforms {min1} but underperforms {max1}.",

    "Try each arm, then stick with the one giving the highest reward.",
    "Explore all arms initially, then exploit the best one.",
    "Allocate choices proportionally to your confidence in each arm's value.",
    "All arms have the same standard deviations, so focus on their means.",
    "The best strategy is to stick to the arm with the highest expected reward."
    ],
  "ntrials": 4
}
